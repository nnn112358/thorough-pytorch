# 3.3 データ読み込み

PyTorch のデータ投入は `Dataset` + `DataLoader` の組み合わせで行います。`Dataset` はデータ形式と変換を定義し、`DataLoader` は反復処理でバッチ単位にデータを供給します。

本節のゴール：

- PyTorch の代表的なデータ読み込み方法
- 自作の読み込みフローを構築できること

柔軟な読み込みのために `Dataset` を継承して自作クラスを定義します。主に次の3つのメソッドを実装します。

- `__init__`: 外部パラメータの受け取り・サンプル集合の準備
- `__getitem__`: 個々のサンプルの読み出し・必要な変換と返却
- `__len__`: サンプル数の返却

例として CIFAR10 風のディレクトリ構成に対しての `ImageFolder` 利用例：

```python
import torch
from torchvision import datasets
train_data = datasets.ImageFolder(train_path, transform=data_transform)
val_data = datasets.ImageFolder(val_path, transform=data_transform)
```

`ImageFolder` はクラスごとのサブディレクトリをもつ画像フォルダからラベル付きで読み込みます。

`data_transform` で反転や切り出しなどの前処理を定義します（次章の実践やノートブックも参照）。

自作 `Dataset` の例：

```python

import os
import pandas as pd
from torchvision.io import read_image

class MyDataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
        """
        Args:
            annotations_file (string): Path to the csv file with annotations.
            img_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
            target_transform (callable, optional): Optional transform to be applied
                on the target.
        """
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        """
        Args:
            idx (int): Index
        """
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        image = read_image(img_path)
        label = self.img_labels.iloc[idx, 1]
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        return image, label
```
ラベル CSV の例：
```csv
image1.jpg, 0
image2.jpg, 1
......
image9.jpg, 9
```
`Dataset` を用意したら、`DataLoader` でバッチ読み込みを行います：

```python
from torch.utils.data import DataLoader

train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, shuffle=True, drop_last=True)
val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=4, shuffle=False)
```

其中:

- batch_size：样本是按“批”读入的，batch_size就是每次读入的样本数
- num_workers：有多少个进程用于读取数据，Windows下该参数设置为0，Linux下常见的为4或者8，根据自己的电脑配置来设置
- shuffle：是否将读入的数据打乱，一般在训练集中设置为True，验证集中设置为False
- drop_last：对于样本最后一部分没有达到批次数的样本，使其不再参与训练

这里可以看一下我们的加载的数据。PyTorch中的DataLoader的读取可以使用next和iter来完成

```python
import matplotlib.pyplot as plt
images, labels = next(iter(val_loader))
print(images.shape)
plt.imshow(images[0].transpose(1,2,0))
plt.show()
```

