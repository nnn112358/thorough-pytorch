# 3.2 基本設定
PyTorch プロジェクトでは、開発をスムーズに進めるために標準的な Python パッケージを読み込みます。代表例は `os` や `numpy` です。あわせて PyTorch 本体のモジュール（`torch`、`torch.nn`、`torch.utils.data.Dataset`、`torch.utils.data.DataLoader`、`torch.optim` など）も利用します。

本節のゴール：

- 深層学習/機械学習でよく使うパッケージ
- GPU 設定の基本

まずは必須パッケージの読み込み例です。ここで示すのは「あくまで一例」です。表データなら `pandas`、画像系なら `cv2`、可視化なら `matplotlib` や `seaborn`、指標計算には `sklearn` など、プロジェクトに応じて追加します。

```python
import os 
import numpy as np 
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.optim as optimizer
```

タスク整理に基づき、後のチューニングを楽にするため代表的なハイパーパラメータをまとめておきます：

- バッチサイズ（batch size）
- 学習率（lr）
- エポック数（max_epochs）
- GPU 設定

```python
batch_size = 16
# バッチサイズ
lr = 1e-4
# 最適化器の学習率
max_epochs = 100
```
ハイパーパラメータはコードに直接書く代わりに、`yaml`、`json`、`dict` などにまとめておく方法も有効です。後からの調整がしやすく、mmdetection、PaddleDetection、detectron2 といったライブラリや多くの AI ラボでも一般的なスタイルです。

デフォルトではデータやモデルは CPU に置かれます。学習を高速化するために GPU を明示して使います。代表的な指定方法は次の2通りです：

```python
# 方法1: os.environ を使う（必要に応じて）
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # 使用する GPU を 0,1 に指定

# 方法2: device を使う。以降 GPU を使う変数に .to(device) を付ける
device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")  # GPU 1 を指定
```

このほか、プロジェクト固有のモジュールやユーザー定義モジュールで使う設定があれば、同様に冒頭でまとめておくと便利です。
