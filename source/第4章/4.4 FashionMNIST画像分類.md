# 基礎実践——FashionMNIST ファッション分類

![](./figures/fashion-mnist-sprite.png)
  
これまでの内容で以下を学びました：  
- PyTorch の基本的な理解
- PyTorch と開発環境のインストール
- 中核となる理論（テンソル＆自動微分）
- PyTorch で深層学習を進める主要ステップと実装の流れ  
  
ここでは基礎的な実践ケースで第1部の知識をつなげ、理解を深めます。以降の発展学習の土台にもなります。

本節のゴール：

- 典型的な深層学習フローの一通り
- 各コンポーネントの実用的な使い方
  
タスクは 10 クラスのファッション画像分類です。データは [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion ) を用います。上図はサンプルです。  
FashionMNIST には学習 60,000 枚、テスト 10,000 枚の 28×28 のグレースケール画像が含まれます。  
  
それでは第3章の各パートを組み合わせ、深層学習フローを順に実装します。

**必要なパッケージを読み込む**  


```python
import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
```

**学習環境とハイパーパラメータ**  



```python
# GPU 設定（2通りの例）
## 方法1：os.environ を使用
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
# 方法2：`device` を使用（以後 `.to(device)`）
device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")

## そのほかのハイパーパラメータ（バッチサイズ、ワーカー数、学習率、エポック数）
batch_size = 256
num_workers = 4   # Windows では 0 を推奨（マルチスレッドの不具合回避）
lr = 1e-4
epochs = 20
```

**データの読み込み**  
ここでは2通りを示します:  
- PyTorch の内蔵データセットを使う  
- CSV を読み込み自作 `Dataset` を用意する  
前者は MNIST、CIFAR10 などの定番データセットで素早く検証する際に便利です。後者は自前データを扱う実務で重要になります。  
  
あわせてサイズの統一や Tensor 化などの変換も行います。
  
これらの変換は `torchvision` で簡単に記述できます。PyTorch は公式/サードパーティを含むエコシステムが充実しています（詳細は後章）。


```python
# まずデータ変換を定義
from torchvision import transforms

image_size = 28
data_transform = transforms.Compose([
    transforms.ToPILImage(),  
     # この手順は読み込み方法に依存。内蔵データセットを使う場合は不要
    transforms.Resize(image_size),
    transforms.ToTensor()
])
```


```python
## 読み込み方法 1：torchvision 付属データセット（ダウンロードに時間がかかる場合あり）
from torchvision import datasets

train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)
test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)
```

    /data1/ljq/anaconda3/envs/smp/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/torch/csrc/utils/tensor_numpy.cpp:180.)
      return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
    


```python
## 読み込み方法 2：CSV を読み込み、自作 Dataset を定義
# CSV ダウンロード先：https://www.kaggle.com/zalando-research/fashionmnist
class FMDataset(Dataset):
    def __init__(self, df, transform=None):
        self.df = df
        self.transform = transform
        self.images = df.iloc[:,1:].values.astype(np.uint8)
        self.labels = df.iloc[:, 0].values
        
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = self.images[idx].reshape(28,28,1)
        label = int(self.labels[idx])
        if self.transform is not None:
            image = self.transform(image)
        else:
            image = torch.tensor(image/255., dtype=torch.float)
        label = torch.tensor(label, dtype=torch.long)
        return image, label

train_df = pd.read_csv("./FashionMNIST/fashion-mnist_train.csv")
test_df = pd.read_csv("./FashionMNIST/fashion-mnist_test.csv")
train_data = FMDataset(train_df, data_transform)
test_data = FMDataset(test_df, data_transform)
```

学習用・評価用データセットを用意したら、学習/評価で使う DataLoader を定義します。  



```python
train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)
test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)
```

読み込み後に簡単な可視化で、データが正しく読めているか確認します。


```python
import matplotlib.pyplot as plt
image, label = next(iter(train_loader))
print(image.shape, label.shape)
plt.imshow(image[0][0], cmap="gray")
```

    torch.Size([256, 1, 28, 28]) 
    torch.Size([256])   
    <matplotlib.image.AxesImage at 0x7f19a043cc10>




    
![png](./figures/output_13_2.png)
    


**モデル設計**  
今回はタスクが比較的単純なため、シンプルな CNN を手作りします（複雑な最新モデルは扱いません）。作成後、GPU で学習します。  



```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, 32, 5),
            nn.ReLU(),
            nn.MaxPool2d(2, stride=2),
            nn.Dropout(0.3),
            nn.Conv2d(32, 64, 5),
            nn.ReLU(),
            nn.MaxPool2d(2, stride=2),
            nn.Dropout(0.3)
        )
        self.fc = nn.Sequential(
            nn.Linear(64*4*4, 512),
            nn.ReLU(),
            nn.Linear(512, 10)
        )
        
    def forward(self, x):
        x = self.conv(x)
        x = x.view(-1, 64*4*4)
        x = self.fc(x)
        # x = nn.functional.normalize(x)
        return x

model = Net()
model = model.cuda()
# model = nn.DataParallel(model).cuda()   # 複数 GPU 学習時の書き方（後章で解説）
```

**損失関数**  
`torch.nn` の CrossEntropy を使用します。PyTorch は整数ラベルを内部で one-hot 相当として扱い、logits（softmax 前）から計算します。ラベルは 0 始まりであること、モデル側で softmax を入れないことに注意します。


```python
criterion = nn.CrossEntropyLoss()
# criterion = nn.CrossEntropyLoss(weight=[1,1,1,1,3,1,1,1,1,1])
```


```python
?nn.CrossEntropyLoss # 重み付け等の戦略を確認
```

**最適化器**  
ここでは Adam を使用します。  


```python
optimizer = optim.Adam(model.parameters(), lr=0.001)
```

**学習と評価（検証）**  
関数に分けて呼び出しやすくします。主な違い：  
- モデル状態の設定  
- オプティマイザの初期化の有無
- 損失の逆伝播の有無
- 各ステップでの更新の有無  
  
加えて、評価時には分類精度も算出します。


```python
def train(epoch):
    model.train()
    train_loss = 0
    for data, label in train_loader:
        data, label = data.cuda(), label.cuda()
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, label)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()*data.size(0)
    train_loss = train_loss/len(train_loader.dataset)
    print('Epoch: {} \tTraining Loss: {:.6f}'.format(epoch, train_loss))
```


```python
def val(epoch):       
    model.eval()
    val_loss = 0
    gt_labels = []
    pred_labels = []
    with torch.no_grad():
        for data, label in test_loader:
            data, label = data.cuda(), label.cuda()
            output = model(data)
            preds = torch.argmax(output, 1)
            gt_labels.append(label.cpu().data.numpy())
            pred_labels.append(preds.cpu().data.numpy())
            loss = criterion(output, label)
            val_loss += loss.item()*data.size(0)
    val_loss = val_loss/len(test_loader.dataset)
    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)
    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)
    print('Epoch: {} \tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))
```


```python
for epoch in range(1, epochs+1):
    train(epoch)
    val(epoch)
```

    /data1/ljq/anaconda3/envs/smp/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)
      return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
    

    Epoch: 1 	Training Loss: 0.659050
    Epoch: 1 	Validation Loss: 0.420328, Accuracy: 0.852000
    Epoch: 2 	Training Loss: 0.403703
    Epoch: 2 	Validation Loss: 0.350373, Accuracy: 0.872300
    Epoch: 3 	Training Loss: 0.350197
    Epoch: 3 	Validation Loss: 0.293053, Accuracy: 0.893200
    Epoch: 4 	Training Loss: 0.322463
    Epoch: 4 	Validation Loss: 0.283335, Accuracy: 0.892300
    Epoch: 5 	Training Loss: 0.300117
    Epoch: 5 	Validation Loss: 0.268653, Accuracy: 0.903500
    Epoch: 6 	Training Loss: 0.282179
    Epoch: 6 	Validation Loss: 0.247219, Accuracy: 0.907200
    Epoch: 7 	Training Loss: 0.268283
    Epoch: 7 	Validation Loss: 0.242937, Accuracy: 0.907800
    Epoch: 8 	Training Loss: 0.257615
    Epoch: 8 	Validation Loss: 0.234324, Accuracy: 0.912200
    Epoch: 9 	Training Loss: 0.245795
    Epoch: 9 	Validation Loss: 0.231515, Accuracy: 0.914100
    Epoch: 10 	Training Loss: 0.238739
    Epoch: 10 	Validation Loss: 0.229616, Accuracy: 0.914400
    Epoch: 11 	Training Loss: 0.230499
    Epoch: 11 	Validation Loss: 0.228124, Accuracy: 0.915200
    Epoch: 12 	Training Loss: 0.221574
    Epoch: 12 	Validation Loss: 0.211928, Accuracy: 0.921200
    Epoch: 13 	Training Loss: 0.217924
    Epoch: 13 	Validation Loss: 0.209744, Accuracy: 0.921700
    Epoch: 14 	Training Loss: 0.206033
    Epoch: 14 	Validation Loss: 0.215477, Accuracy: 0.921400
    Epoch: 15 	Training Loss: 0.203349
    Epoch: 15 	Validation Loss: 0.215550, Accuracy: 0.919400
    Epoch: 16 	Training Loss: 0.196319
    Epoch: 16 	Validation Loss: 0.210800, Accuracy: 0.923700
    Epoch: 17 	Training Loss: 0.191969
    Epoch: 17 	Validation Loss: 0.207266, Accuracy: 0.923700
    Epoch: 18 	Training Loss: 0.185466
    Epoch: 18 	Validation Loss: 0.207138, Accuracy: 0.924200
    Epoch: 19 	Training Loss: 0.178241
    Epoch: 19 	Validation Loss: 0.204093, Accuracy: 0.924900
    Epoch: 20 	Training Loss: 0.176674
    Epoch: 20 	Validation Loss: 0.197495, Accuracy: 0.928300
    

**モデルの保存**  
学習後は `torch.save` でモデルパラメータやモデル本体を保存できます（学習途中の保存も可）。
詳細は後の章で解説します。


```python
save_path = "./FahionModel.pkl"
torch.save(model, save_path)
```

**演習**
- 学習関連
1. 6.2「学習率の動的調整」を使って学習率スケジュールを適用して学習する。
2. 6.3「モデル微調整」で学んだ事前学習モデルを用い、微調整の効果を確認する。
3. 6.5「データ拡張」で `imgaug` による拡張を試し、効果を確認する。
4. 7.3「TensorBoard で可視化」を用い、学習過程を可視化する。
5. 複数 GPU で学習し、効果を比較する。

- 推論関連
1. 5.4「PyTorch モデルの保存と読み込み」を用い、保存済みモデルを読み込んで推論する。
2. `sklearn.metrics.classification_report` で分類レポートを出力する。
3. 9.1「ONNX でデプロイと推論」を参照し、ONNX へ変換して ONNX Runtime で推論する。
